{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, label_cols=None, preprocess_fn=None):\n",
    "        self.feature_cols = feature_cols\n",
    "        self.label_cols = label_cols\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "        # データの前処理\n",
    "        if preprocess_fn:\n",
    "            self.data = preprocess_fn(df[feature_cols])\n",
    "        else:\n",
    "            self.data = df[feature_cols].values\n",
    "        \n",
    "        self.labels = df[label_cols].values if label_cols else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.data[idx]\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return torch.FloatTensor(feature), torch.FloatTensor(label)\n",
    "        return torch.FloatTensor(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNetwork(nn.Module):\n",
    "    def __init__(self, z_size, hidden_size, output_size):\n",
    "        super(GeneratorNetwork, self).__init__()\n",
    "        # input -> all, LR -> 100 -> all, tanh -> 784 -> output\n",
    "        # 1st layer: all\n",
    "        self.fc1 = nn.Linear(z_size, hidden_size)\n",
    "        # Leaky ReLU\n",
    "        # 2nd layer: all\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # tanh\n",
    "        # 3rd layer: all\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, z):\n",
    "        z = F.leaky_relu(self.fc1(z), negative_slope=0.2)\n",
    "        z = F.tanh(self.fc2(z))\n",
    "        return self.fc3(z)\n",
    "\n",
    "\n",
    "class DiscriminatorNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "        # input -> 784 -> all, LR -> 100 -> all, sig -> 1 -> output\n",
    "        # 1st layer: all\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # Leaky ReLU\n",
    "        # 2nd layer: all\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # Leaky ReLU\n",
    "        # 3rd layer: all\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        # sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=0.2)\n",
    "        return F.sigmoid(self.fc3(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(gen_model, disc_model, real_input, batch_size, z_size):\n",
    "    # uniform random\n",
    "    input_z = torch.rand(batch_size, z_size)\n",
    "    fake_data = gen_model(input_z)\n",
    "\n",
    "    real_output = disc_model(real_input)\n",
    "    real_loss = F.binary_cross_entropy(\n",
    "        real_output,\n",
    "        torch.ones_like(real_output)\n",
    "    )\n",
    "\n",
    "    fake_output = disc_model(fake_data.detach())\n",
    "    fake_loss = F.binary_cross_entropy(\n",
    "        fake_output,\n",
    "        torch.zeros_like(fake_output)\n",
    "    )\n",
    "\n",
    "    d_loss = fake_loss + real_loss\n",
    "\n",
    "    re_fake_output = disc_model(fake_data)\n",
    "    g_loss = F.binary_cross_entropy(\n",
    "        fake_output,\n",
    "        torch.ones_like(fake_output)\n",
    "    )\n",
    "\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, dataloader, num_epochs, z_dim):\n",
    "    timing = num_epochs / 2\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for _, (real_data, _) in enumerate(dataloader):\n",
    "            batch_size = 16\n",
    "            \n",
    "            # 識別器の学習\n",
    "            d_optimizer.zero_grad()\n",
    "            d_loss, _ = train_step(generator, discriminator, real_data, batch_size, z_dim)\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # 生成器の学習\n",
    "            g_optimizer.zero_grad()\n",
    "            _, g_loss = train_step(generator, discriminator, real_data, batch_size, z_dim)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # if i % 500 == 0:\n",
    "            #     print(f\"\\rEpoch {epoch:4d} ... {i:10d} // {len(dataloader)}\", end=\"\")\n",
    "        if (epoch + 1) % timing == 0:\n",
    "            print(f\"Epoch {epoch:4d} completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df):\n",
    "    columns = df.columns.tolist()\n",
    "    feature_cols = [col for col in columns if col != \"Label\" and col != \"Attempted Category\"]\n",
    "    label_cols = [\"Label\"]\n",
    "\n",
    "    label = df[\"Label\"].unique().tolist()\n",
    "    if len(label) != 1:\n",
    "        raise ValueError(f\"Label must be unique: {label}\")\n",
    "    \n",
    "    dataset = DataFrameDataset(\n",
    "        df,\n",
    "        feature_cols,\n",
    "        label_cols,\n",
    "        preprocess_fn=None\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    data_column_size = len(feature_cols)\n",
    "    z_size = data_column_size\n",
    "    gen_hidden_size = 100\n",
    "    disc_hidden_size = 100\n",
    "    epochs = 10_000\n",
    "\n",
    "    gen_model = GeneratorNetwork(z_size, gen_hidden_size, data_column_size)\n",
    "    disc_model = DiscriminatorNetwork(data_column_size, disc_hidden_size)\n",
    "\n",
    "    train_gan(gen_model, disc_model, dataloader, epochs, data_column_size)\n",
    "    torch.save(gen_model.state_dict(), f\"../result/gan/gen_model_{label}.pth\")\n",
    "    torch.save(disc_model.state_dict(), f\"../result/gan/disc_model_{label}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099971, 67)\n",
      "Skipping label: 0, count: 1582561\n",
      "Training for label: 13, count: 12\n",
      "===== Epoch    0 completed ==========\n",
      "===== Epoch 5000 completed ==========\n",
      "Training for label: 12, count: 3972\n",
      "===== Epoch    0 completed ==========\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = os.path.abspath(\"../data_cicids2017/1_formated/cicids2017_formated.csv\")\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "df = df.drop(columns=[\"Attempted Category\"])\n",
    "print(df.shape)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"Label\"] = le.fit_transform(df[\"Label\"])\n",
    "labels = df[\"Label\"].unique()\n",
    "\n",
    "for label in labels:\n",
    "    df_label = df[df[\"Label\"] == label]\n",
    "    if len(df_label) < 100_000:\n",
    "        print(f\"=== Training for label: {label}, count: {len(df_label)} ===\")\n",
    "        train(df_label)\n",
    "    else:\n",
    "        print(f\"=== Skipping label: {label}, count: {len(df_label)} ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
