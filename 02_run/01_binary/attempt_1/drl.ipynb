{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import flow_package as f_p\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:14<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "CONST = f_p.Const()\n",
    "\n",
    "TRAIN_DIR = \"../../../data_cicids2017/1_sampling\"\n",
    "\n",
    "files_path = glob(f\"{TRAIN_DIR}/*.csv\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file_path in tqdm(files_path):\n",
    "    df_tmp = pd.read_csv(file_path)\n",
    "    df_tmp = df_tmp.dropna()\n",
    "    df_tmp = df_tmp.drop_duplicates()\n",
    "    df = pd.concat([df, df_tmp], axis=0)\n",
    "\n",
    "# Label\n",
    "le = LabelEncoder()\n",
    "df[\"Label\"] = le.fit_transform(df[\"Label\"])\n",
    "\n",
    "df[\"Label\"] = df[\"Label\"].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_package.binary_flow_env import BinaryFlowEnv, InputType\n",
    "\n",
    "train_input = InputType(\n",
    "    input_features=train_df.drop(columns=[\"Label\"]),\n",
    "    input_labels=train_df[\"Label\"],\n",
    "    reward_list=[1.0, -1.0],\n",
    ")\n",
    "\n",
    "test_input = InputType(\n",
    "    input_features=test_df.drop(columns=[\"Label\"]),\n",
    "    input_labels=test_df[\"Label\"],\n",
    "    reward_list=[1.0, -1.0],\n",
    ")\n",
    "\n",
    "train_env = BinaryFlowEnv(train_input)\n",
    "test_env = BinaryFlowEnv(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transaction = namedtuple('Transaction', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        # self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transaction(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "\n",
    "def plot_graph(data: list, show_result=False):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    # durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "\n",
    "    if show_result:\n",
    "        plt.title(\"Result\")\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title(\"Training...\")\n",
    "    \n",
    "    means = moving_average(data, 50)\n",
    "\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"ratio\")\n",
    "    plt.plot(data, color=\"lemonchiffon\")\n",
    "    plt.plot(means, color=\"red\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict: dict, show_result=False):\n",
    "    fig = plt.figure(figsize=(16, 20))\n",
    "\n",
    "    ac = fig.add_subplot(5, 1, 1)\n",
    "    ac.plot(metrics_dict[\"accuracy\"], label=\"accuracy\")\n",
    "    ac.grid()\n",
    "    ac.set_title(\"Accuracy\")\n",
    "\n",
    "    pr = fig.add_subplot(5, 1, 2)\n",
    "    pr.plot(metrics_dict[\"precision\"], label=\"precision\", color=\"green\")\n",
    "    pr.grid()\n",
    "    pr.set_title(\"Precision\")\n",
    "\n",
    "    re = fig.add_subplot(5, 1, 3)\n",
    "    re.plot(metrics_dict[\"recall\"], label=\"recall\", color=\"red\")\n",
    "    re.grid()\n",
    "    re.set_title(\"Recall\")\n",
    "\n",
    "    f1 = fig.add_subplot(5, 1, 4)\n",
    "    f1.plot(metrics_dict[\"f1\"], label=\"f1\", color=\"black\")\n",
    "    f1.grid()\n",
    "    f1.set_title(\"F1\")\n",
    "\n",
    "    fpr = fig.add_subplot(5, 1, 5)\n",
    "    fpr.plot(metrics_dict[\"fpr\"], label=\"fpr\", color=\"purple\")\n",
    "    fpr.grid()\n",
    "    fpr.set_title(\"FPR\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, tn, fp, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp) if tp + fp != 0 else -1\n",
    "    recall = tp / (tp + fn) if tp + fn != 0 else -1\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall != 0 else None\n",
    "    fpr = fp / (fp + tn) if fp + tn != 0 else None\n",
    "\n",
    "    if precision < 0:\n",
    "        precision = None\n",
    "    if recall < 0:\n",
    "        recall = None\n",
    "    return accuracy, precision, recall, f1, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT_DIM = 32\n",
    "class DeepFlowNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(DeepFlowNetwork, self).__init__()\n",
    "\n",
    "        self.protocol_embedding = nn.Embedding(256, 8) # -> 8\n",
    "        self.port_embedding = nn.Embedding(65536, PORT_DIM) # -> 8\n",
    "        # other inputs are not embedding: n_inputs - 2\n",
    "\n",
    "        # all inputs: n_inputs - 2 + 8 + 8 = n_inputs + 14\n",
    "        n_inputs = n_inputs + 6 + PORT_DIM\n",
    "\n",
    "        self.fc1 = nn.Linear(n_inputs, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        port_emb = self.port_embedding(x[0].long())\n",
    "        protocol_emb = self.protocol_embedding(x[1].long())\n",
    "\n",
    "        # print(port_emb.shape, protocol_emb.shape, x[2].shape)\n",
    "\n",
    "        renew = torch.cat([port_emb, protocol_emb, x[2]], dim=1)\n",
    "\n",
    "        renew = F.relu(self.fc1(renew))\n",
    "        renew = F.relu(self.fc2(renew))\n",
    "        return self.fc3(renew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_TARGET_STEPS = 200\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 100000\n",
    "TAU = 0.005\n",
    "LR = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m state \u001b[38;5;241m=\u001b[39m train_env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(info)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m policy_net \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFlowNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_actions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m target_net \u001b[38;5;241m=\u001b[39m DeepFlowNetwork(n_inputs, n_actions)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m target_net\u001b[38;5;241m.\u001b[39mload_state_dict(policy_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "n_actions = train_env.action_space.n\n",
    "n_inputs = train_env.observation_space.shape[0]\n",
    "\n",
    "# print(f\"n_inputs: {n_inputs}, n_actions: {n_actions}\")\n",
    "\n",
    "state = train_env.reset()\n",
    "# print(info)\n",
    "\n",
    "policy_net = DeepFlowNetwork(n_inputs, n_actions).to(device)\n",
    "target_net = DeepFlowNetwork(n_inputs, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.SGD(policy_net.parameters(), lr=LR)\n",
    "steps_done = 0\n",
    "\n",
    "memory = ReplayMemory(10000)\n",
    "episode_rewards = []\n",
    "episode_precision = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state_tensor: torch.Tensor):\n",
    "    # print(f\"state_tensor: {state_tensor[0,1]}\")\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # print(policy_net(state_tensor))\n",
    "            # print(policy_net(state_tensor).max(1))\n",
    "            return policy_net(state_tensor).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], dtype=torch.long, device=device)\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transaction(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(\n",
    "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
    "        device=device,\n",
    "        dtype=torch.bool\n",
    "    )\n",
    "    # non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "    # print(batch.state[0])\n",
    "    state_batch_port = torch.cat([s[0] for s in batch.state])\n",
    "    state_batch_protocol = torch.cat([s[1] for s in batch.state])\n",
    "    state_batch_other = torch.cat([s[2] for s in batch.state])\n",
    "\n",
    "    state_batch = [state_batch_port, state_batch_protocol, state_batch_other]\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    # non_final_next_states も同様に処理\n",
    "    non_final_next_states_port = torch.cat([s[0] for s in batch.next_state if s is not None])\n",
    "    non_final_next_states_protocol = torch.cat([s[1] for s in batch.next_state if s is not None])\n",
    "    non_final_next_states_features = torch.cat([s[2] for s in batch.next_state if s is not None])\n",
    "    non_final_next_states = [non_final_next_states_port, non_final_next_states_protocol, non_final_next_states_features]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "\n",
    "    expected_state_action_values = reward_batch + GAMMA * next_state_values\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    utils.clip_grad_value_(policy_net.parameters(), 1000)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    random.seed(i_episode)\n",
    "    sum_reward = 0\n",
    "    confusion_matrix = np.zeros((2,2), dtype=int)\n",
    "\n",
    "    initial_state = train_env.reset()\n",
    "    # state = torch.tensor(initial_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "    state = f_p.to_tensor(initial_state, device)\n",
    "\n",
    "    for t in count():\n",
    "        # select action\n",
    "        action = select_action(state)\n",
    "\n",
    "        # print(action)\n",
    "        # calculate next state\n",
    "        raw_next_state, reward, terminated, truncated, info = train_env.step(action.item())\n",
    "        row_column_index = info[\"matrix_position\"]\n",
    "        # print(info)\n",
    "        confusion_matrix[row_column_index[0], row_column_index[1]] += 1\n",
    "        # print(info)\n",
    "\n",
    "        # to tensor\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            # next_state = torch.tensor(raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "            next_state = f_p.to_tensor(raw_next_state, device)\n",
    "        reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "\n",
    "        # store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        sum_reward += reward.item() if reward.item() == 1 else 0\n",
    "\n",
    "        # move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # optimize the model\n",
    "        # print(\"optimize_model\")\n",
    "        optimize_model()\n",
    "\n",
    "        if terminated:\n",
    "            episode_rewards.append(sum_reward / (t + 1))\n",
    "            break\n",
    "\n",
    "    # do after the episode\n",
    "    # episode_rewards.append(sum_reward)\n",
    "    base = confusion_matrix[1, 1] + confusion_matrix[1, 0]\n",
    "    episode_precision.append(\n",
    "        confusion_matrix[1, 1] / base if base != 0 else 0\n",
    "    )\n",
    "    # print(i_episode)\n",
    "    if i_episode > 0 and i_episode % 10 == 0:\n",
    "        plot_graph(episode_precision)\n",
    "\n",
    "# complete the episode\n",
    "plot_graph(episode_precision, show_result=True)\n",
    "torch.save(policy_net.state_dict(), \"re_01_dqn_cic.pth\")  # save the model\n",
    "\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"re_01_dqn_cic.pth\"\n",
    "\n",
    "# load the model\n",
    "trained_network = DeepFlowNetwork(n_inputs=n_inputs, n_outputs=n_actions).to(device)\n",
    "trained_network.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "trained_network.eval()\n",
    "\n",
    "# test the model\n",
    "\n",
    "confusion_array = np.zeros((2, 2), dtype=np.int32)\n",
    "metrics_dictionary = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"fpr\": []\n",
    "}\n",
    "\n",
    "for i_loop in range(10):\n",
    "    random.seed(i_loop)\n",
    "    test_raw_state = test_env.reset()\n",
    "    try:\n",
    "        test_state = f_p.to_tensor(test_raw_state, device)\n",
    "    except:\n",
    "        raise print(test_raw_state)\n",
    "    for t in count():\n",
    "        with torch.no_grad():\n",
    "            test_action = trained_network(test_state).max(1).indices.view(1, 1)\n",
    "\n",
    "        test_raw_next_state, test_reward, test_terminated, test_truncated, test_info = test_env.step(test_action.item())\n",
    "        # print(test_info)\n",
    "        # calculate confusion matrix\n",
    "        raw = 0 if test_reward == 1 else 1\n",
    "\n",
    "        # test_info = (row, column) means confusion matrix index\n",
    "        index = test_info[\"matrix_position\"]\n",
    "        confusion_array[index[0], index[1]] += 1\n",
    "\n",
    "        # print(index)\n",
    "\n",
    "        if test_terminated:\n",
    "            break\n",
    "\n",
    "        # make next state tensor and update state\n",
    "        #test_state = torch.tensor(test_raw_next_state, device=device, dtype=torch.float32).unsqueeze(0)\n",
    "        test_state = f_p.to_tensor(test_raw_next_state, device)\n",
    "\n",
    "    # calculate metrics\n",
    "    tp = confusion_array[1, 1]\n",
    "    tn = confusion_array[0, 0]\n",
    "    fp = confusion_array[1, 0]\n",
    "    fn = confusion_array[0, 1]\n",
    "    print(f\"{i_loop + 1:5}, {tp:7}, {tn:7}, {fp:7}, {fn:7}\")\n",
    "\n",
    "    accuracy, precision, recall, f1, fpr = calculate_metrics(tp, tn, fp, fn)\n",
    "    metrics_dictionary[\"accuracy\"].append(accuracy)\n",
    "    metrics_dictionary[\"precision\"].append(precision)\n",
    "    metrics_dictionary[\"recall\"].append(recall)\n",
    "    metrics_dictionary[\"f1\"].append(f1)\n",
    "    metrics_dictionary[\"fpr\"].append(fpr)\n",
    "    # print(accuracy, precision, recall, f1, fpr)\n",
    "\n",
    "\n",
    "    # if i_loop % 50 == 0:\n",
    "    #     print(f\"{i_loop + 1:5}, {tp:7}, {tn:7}, {fp:7}, {fn:7}\")\n",
    "\n",
    "# plot metrics\n",
    "plot_metrics(metrics_dictionary, show_result=True)\n",
    "print(f\" accuracy: {metrics_dictionary['accuracy'][-1]}\")\n",
    "print(f\"precision: {metrics_dictionary['precision'][-1]}\")\n",
    "print(f\"  recall : {metrics_dictionary['recall'][-1]}\")\n",
    "print(f\"    f1   : {metrics_dictionary['f1'][-1]}\")\n",
    "print(f\"   fpr   : {metrics_dictionary['fpr'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
